{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas and NumPy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Supress Warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the CSV file and preparing a dataframe(Path of the file has to be changed accordingly)\n",
    "\n",
    "df = pd.read_csv(\"D://UpGrad//UpGrad//Module 3 Machine Learning 2//7. Telecom case study//telecom_churn_data.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(percentiles=[.25,.5,.75,.90,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns with standard deviation = 0 \n",
    "\n",
    "nunique = df.apply(pd.Series.nunique)\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "print(cols_to_drop)\n",
    "df.drop(cols_to_drop, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the percentage of missing values\n",
    "\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(percentiles=[.25,.5,.75,.90,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing null values in \"onnet_mou\" column\n",
    "\n",
    "df[[\"onnet_mou_6\",\"onnet_mou_7\",\"onnet_mou_8\",\"onnet_mou_9\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the above columns for outliers \n",
    "\n",
    "plot=[\"onnet_mou_6\",\"onnet_mou_7\",\"onnet_mou_8\",\"onnet_mou_9\"]\n",
    "\n",
    "for i in plot:\n",
    "    sns.boxplot(y=df[i])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above plots, it can be stated that imputing median value in place of null values is recommended because of presence of outliers.\n",
    "\n",
    "for i in plot:\n",
    "    df[i] = df[i].fillna(df[i].median())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing null values in \"offnet_mou\" column\n",
    "# plotting the columns for outliers \n",
    "\n",
    "\n",
    "df[[\"offnet_mou_6\",\"offnet_mou_7\",\"offnet_mou_8\",\"offnet_mou_9\"]].head()\n",
    "plot=[\"offnet_mou_6\",\"offnet_mou_7\",\"offnet_mou_8\",\"offnet_mou_9\"]\n",
    "\n",
    "for i in plot:\n",
    "    sns.boxplot(y=df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above plots, it can be stated that imputing median value in place of null values is recommended because of presence of outliers.\n",
    "\n",
    "for i in plot:\n",
    "    df[i] = df[i].fillna(df[i].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing null values in \"roam_ic_mou*\" & \"roam_og_mou*\"columns\n",
    "# plotting the columns for outliers \n",
    "\n",
    "\n",
    "print(df[[\"roam_ic_mou_6\",\"roam_ic_mou_7\",\"roam_ic_mou_8\",\"roam_ic_mou_9\",\"roam_og_mou_6\",\"roam_og_mou_7\",\"roam_og_mou_8\",\"roam_og_mou_9\"]].head())\n",
    "plot=[\"roam_ic_mou_6\",\"roam_ic_mou_7\",\"roam_ic_mou_8\",\"roam_ic_mou_9\",\"roam_og_mou_6\",\"roam_og_mou_7\",\"roam_og_mou_8\",\"roam_og_mou_9\"]\n",
    "\n",
    "for i in plot:\n",
    "    sns.boxplot(y=df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above plots, it can be stated that imputing median value in place of null values is recommended because of presence of outliers.\n",
    "\n",
    "for i in plot:\n",
    "    df[i] = df[i].fillna(df[i].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the percentage of missing values\n",
    "\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing null values in \"loc_og_t2t_mou*\",\"loc_og_t2m_mou*\",\"loc_og_t2f_mou*\" & \"loc_og_t2c_mou*\"columns\n",
    "# plotting the columns for outliers\n",
    "\n",
    "print(df[[\"loc_og_t2t_mou_6\",\"loc_og_t2t_mou_7\",\"loc_og_t2t_mou_8\",\"loc_og_t2t_mou_9\",\"loc_og_t2m_mou_6\",\"loc_og_t2m_mou_7\",\"loc_og_t2m_mou_8\",\"loc_og_t2m_mou_9\",\"loc_og_t2f_mou_6\",\"loc_og_t2f_mou_7\",\"loc_og_t2f_mou_8\",\"loc_og_t2f_mou_9\",\"loc_og_t2c_mou_6\",\"loc_og_t2c_mou_7\",\"loc_og_t2c_mou_8\",\"loc_og_t2c_mou_9\"]].head())\n",
    "plot=[\"loc_og_t2t_mou_6\",\"loc_og_t2t_mou_7\",\"loc_og_t2t_mou_8\",\"loc_og_t2t_mou_9\",\"loc_og_t2m_mou_6\",\"loc_og_t2m_mou_7\",\"loc_og_t2m_mou_8\",\"loc_og_t2m_mou_9\",\"loc_og_t2f_mou_6\",\"loc_og_t2f_mou_7\",\"loc_og_t2f_mou_8\",\"loc_og_t2f_mou_9\",\"loc_og_t2c_mou_6\",\"loc_og_t2c_mou_7\",\"loc_og_t2c_mou_8\",\"loc_og_t2c_mou_9\"]\n",
    "\n",
    "for i in plot:\n",
    "    sns.boxplot(y=df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above plots, it can be stated that imputing median value in place of null values is recommended because of presence of outliers.\n",
    "\n",
    "for i in plot:\n",
    "    df[i] = df[i].fillna(df[i].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['fb_user_6', 'fb_user_7', 'fb_user_8', 'fb_user_9']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data of the following columns\n",
    "\n",
    "print(df['fb_user_6'].astype('category').value_counts())\n",
    "print(df['fb_user_7'].astype('category').value_counts())\n",
    "print(df['fb_user_8'].astype('category').value_counts())\n",
    "print(df['fb_user_9'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to the data dictionary this column indicates whether the user avails social networking services or not. Hence, zero value can be imputed in place of Nan values.\n",
    "\n",
    "df['fb_user_6'] = df['fb_user_6'].fillna(0.0)\n",
    "df['fb_user_7'] = df['fb_user_7'].fillna(0.0)\n",
    "df['fb_user_8'] = df['fb_user_8'].fillna(0.0)\n",
    "df['fb_user_9'] = df['fb_user_9'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data of the following columns\n",
    "\n",
    "print(df['night_pck_user_6'].astype('category').value_counts())\n",
    "print(df['night_pck_user_7'].astype('category').value_counts())\n",
    "print(df['night_pck_user_8'].astype('category').value_counts())\n",
    "print(df['night_pck_user_9'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to the data dictionary this column indicates whether the user avails night packs or not. Hence, zero value can be imputed in place of Nan values.\n",
    "\n",
    "df['night_pck_user_6'] = df['night_pck_user_6'].fillna(0.0)\n",
    "df['night_pck_user_7'] = df['night_pck_user_7'].fillna(0.0)\n",
    "df['night_pck_user_8'] = df['night_pck_user_8'].fillna(0.0)\n",
    "df['night_pck_user_9'] = df['night_pck_user_9'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the percentage of missing values\n",
    "\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data of the following columns\n",
    "\n",
    "print(df['arpu_2g_6'].astype('category').value_counts())\n",
    "print(df['arpu_2g_7'].astype('category').value_counts())\n",
    "print(df['arpu_2g_8'].astype('category').value_counts())\n",
    "print(df['arpu_2g_9'].astype('category').value_counts())\n",
    "print(df['arpu_3g_6'].astype('category').value_counts())\n",
    "print(df['arpu_3g_7'].astype('category').value_counts())\n",
    "print(df['arpu_3g_8'].astype('category').value_counts())\n",
    "print(df['arpu_3g_9'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After analyzing the above columns, it is better to drop the above columns since there are high percentage of null values\n",
    "\n",
    "df = df.drop(['arpu_2g_6','arpu_2g_7','arpu_2g_8','arpu_2g_9','arpu_3g_6','arpu_3g_7','arpu_3g_8','arpu_3g_9'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['loc_og_mou_6'].astype('category').value_counts())\n",
    "print(df['loc_og_mou_7'].astype('category').value_counts())\n",
    "print(df['loc_og_mou_8'].astype('category').value_counts())\n",
    "print(df['loc_og_mou_9'].astype('category').value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing null values in \"offnet_mou\" column\n",
    "# plotting the columns for outliers \n",
    "\n",
    "plot=[\"loc_og_mou_6\",\"loc_og_mou_7\",\"loc_og_mou_8\",\"loc_og_mou_9\"]\n",
    "\n",
    "for i in plot:\n",
    "    sns.boxplot(y=df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above plots, it can be stated that imputing median value in place of null values is recommended because of presence of outliers.\n",
    "\n",
    "for i in plot:\n",
    "    df[i] = df[i].fillna(df[i].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the below columns\n",
    "\n",
    "print(df['std_og_t2t_mou_6'].astype('category').value_counts())\n",
    "print(df['std_og_t2t_mou_7'].astype('category').value_counts())\n",
    "print(df['std_og_t2t_mou_8'].astype('category').value_counts())\n",
    "print(df['std_og_t2t_mou_9'].astype('category').value_counts())\n",
    "print(df['std_og_t2m_mou_6'].astype('category').value_counts())\n",
    "print(df['std_og_t2m_mou_7'].astype('category').value_counts())\n",
    "print(df['std_og_t2m_mou_8'].astype('category').value_counts())\n",
    "print(df['std_og_t2m_mou_9'].astype('category').value_counts())\n",
    "print(df['std_og_t2f_mou_6'].astype('category').value_counts())\n",
    "print(df['std_og_t2f_mou_7'].astype('category').value_counts())\n",
    "print(df['std_og_t2f_mou_8'].astype('category').value_counts())\n",
    "print(df['std_og_t2f_mou_9'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot=[\"std_og_t2t_mou_6\",\"std_og_t2t_mou_7\",\"std_og_t2t_mou_8\",\"std_og_t2t_mou_9\",\"std_og_t2m_mou_6\",\"std_og_t2m_mou_7\",\"std_og_t2m_mou_8\",\"std_og_t2m_mou_9\",\"std_og_t2f_mou_6\",\"std_og_t2f_mou_7\",\"std_og_t2f_mou_8\",\"std_og_t2f_mou_9\"]\n",
    "\n",
    "for i in plot:\n",
    "    sns.boxplot(y=df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above plots, it can be stated that imputing median value in place of null values is recommended because of presence of outliers.\n",
    "\n",
    "for i in plot:\n",
    "    df[i] = df[i].fillna(df[i].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the below columns\n",
    "\n",
    "print(df['std_og_mou_6'].astype('category').value_counts())\n",
    "print(df['std_og_mou_7'].astype('category').value_counts())\n",
    "print(df['std_og_mou_8'].astype('category').value_counts())\n",
    "print(df['std_og_mou_9'].astype('category').value_counts())\n",
    "print(df['isd_og_mou_6'].astype('category').value_counts())\n",
    "print(df['isd_og_mou_7'].astype('category').value_counts())\n",
    "print(df['isd_og_mou_8'].astype('category').value_counts())\n",
    "print(df['isd_og_mou_9'].astype('category').value_counts())\n",
    "print(df['spl_og_mou_6'].astype('category').value_counts())\n",
    "print(df['spl_og_mou_7'].astype('category').value_counts())\n",
    "print(df['spl_og_mou_8'].astype('category').value_counts())\n",
    "print(df['spl_og_mou_9'].astype('category').value_counts())\n",
    "print(df['og_others_6'].astype('category').value_counts())\n",
    "print(df['og_others_7'].astype('category').value_counts())\n",
    "print(df['og_others_8'].astype('category').value_counts())\n",
    "print(df['og_others_9'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot=[\"std_og_mou_6\",\"std_og_mou_7\",\"std_og_mou_8\",\"std_og_mou_9\",\"isd_og_mou_6\",\"isd_og_mou_7\",\"isd_og_mou_8\",\"isd_og_mou_9\",\"spl_og_mou_6\",\"spl_og_mou_7\",\"spl_og_mou_8\",\"spl_og_mou_9\",\"og_others_6\",\"og_others_7\",\"og_others_8\",\"og_others_9\"]\n",
    "\n",
    "for i in plot:\n",
    "    sns.boxplot(y=df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above plots, it can be stated that imputing median value in place of null values is recommended because of presence of outliers.\n",
    "\n",
    "for i in plot:\n",
    "    df[i] = df[i].fillna(df[i].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the below columns\n",
    "\n",
    "print(df['loc_ic_t2t_mou_6'].astype('category').value_counts())\n",
    "print(df['loc_ic_t2t_mou_7'].astype('category').value_counts())\n",
    "print(df['loc_ic_t2t_mou_8'].astype('category').value_counts())\n",
    "print(df['loc_ic_t2t_mou_9'].astype('category').value_counts())\n",
    "print(df['loc_ic_t2m_mou_6'].astype('category').value_counts())\n",
    "print(df['loc_ic_t2m_mou_7'].astype('category').value_counts())\n",
    "print(df['loc_ic_t2m_mou_8'].astype('category').value_counts())\n",
    "print(df['loc_ic_t2m_mou_9'].astype('category').value_counts())\n",
    "print(df['loc_ic_t2f_mou_6'].astype('category').value_counts())\n",
    "print(df['loc_ic_t2f_mou_7'].astype('category').value_counts())\n",
    "print(df['loc_ic_t2f_mou_8'].astype('category').value_counts())\n",
    "print(df['loc_ic_t2f_mou_9'].astype('category').value_counts())\n",
    "print(df['loc_ic_mou_6'].astype('category').value_counts())\n",
    "print(df['loc_ic_mou_7'].astype('category').value_counts())\n",
    "print(df['loc_ic_mou_8'].astype('category').value_counts())\n",
    "print(df['loc_ic_mou_9'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot=[\"loc_ic_t2t_mou_6\",\"loc_ic_t2t_mou_7\",\"loc_ic_t2t_mou_8\",\"loc_ic_t2t_mou_9\",\"loc_ic_t2m_mou_6\",\"loc_ic_t2m_mou_7\",\"loc_ic_t2m_mou_8\",\"loc_ic_t2m_mou_9\",\"loc_ic_t2f_mou_6\",\"loc_ic_t2f_mou_7\",\"loc_ic_t2f_mou_8\",\"loc_ic_t2f_mou_9\",\"loc_ic_mou_6\",\"loc_ic_mou_7\",\"loc_ic_mou_8\",\"loc_ic_mou_9\"]\n",
    "\n",
    "for i in plot:\n",
    "    sns.boxplot(y=df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above plots, it can be stated that imputing median value in place of null values is recommended because of presence of outliers.\n",
    "\n",
    "for i in plot:\n",
    "    df[i] = df[i].fillna(df[i].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the below columns\n",
    "\n",
    "print(df['std_ic_t2t_mou_6'].astype('category').value_counts())\n",
    "print(df['std_ic_t2t_mou_7'].astype('category').value_counts())\n",
    "print(df['std_ic_t2t_mou_8'].astype('category').value_counts())\n",
    "print(df['std_ic_t2t_mou_9'].astype('category').value_counts())\n",
    "print(df['std_ic_t2m_mou_6'].astype('category').value_counts())\n",
    "print(df['std_ic_t2m_mou_7'].astype('category').value_counts())\n",
    "print(df['std_ic_t2m_mou_8'].astype('category').value_counts())\n",
    "print(df['std_ic_t2m_mou_9'].astype('category').value_counts())\n",
    "print(df['std_ic_t2f_mou_6'].astype('category').value_counts())\n",
    "print(df['std_ic_t2f_mou_7'].astype('category').value_counts())\n",
    "print(df['std_ic_t2f_mou_8'].astype('category').value_counts())\n",
    "print(df['std_ic_t2f_mou_9'].astype('category').value_counts())\n",
    "print(df['std_ic_mou_6'].astype('category').value_counts())\n",
    "print(df['std_ic_mou_7'].astype('category').value_counts())\n",
    "print(df['std_ic_mou_8'].astype('category').value_counts())\n",
    "print(df['std_ic_mou_9'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot=[\"std_ic_t2t_mou_6\",\"std_ic_t2t_mou_7\",\"std_ic_t2t_mou_8\",\"std_ic_t2t_mou_9\",\"std_ic_t2m_mou_6\",\"std_ic_t2m_mou_7\",\"std_ic_t2m_mou_8\",\"std_ic_t2m_mou_9\",\"std_ic_t2f_mou_6\",\"std_ic_t2f_mou_7\",\"std_ic_t2f_mou_8\",\"std_ic_t2f_mou_9\",\"std_ic_mou_6\",\"std_ic_mou_7\",\"std_ic_mou_8\",\"std_ic_mou_9\"]\n",
    "\n",
    "for i in plot:\n",
    "    sns.boxplot(y=df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above plots, it can be stated that imputing median value in place of null values is recommended because of presence of outliers.\n",
    "\n",
    "for i in plot:\n",
    "    df[i] = df[i].fillna(df[i].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the below columns\n",
    "\n",
    "print(df['isd_ic_mou_6'].astype('category').value_counts())\n",
    "print(df['isd_ic_mou_7'].astype('category').value_counts())\n",
    "print(df['isd_ic_mou_8'].astype('category').value_counts())\n",
    "print(df['isd_ic_mou_9'].astype('category').value_counts())\n",
    "print(df['spl_ic_mou_6'].astype('category').value_counts())\n",
    "print(df['spl_ic_mou_7'].astype('category').value_counts())\n",
    "print(df['spl_ic_mou_8'].astype('category').value_counts())\n",
    "print(df['spl_ic_mou_9'].astype('category').value_counts())\n",
    "print(df['ic_others_6'].astype('category').value_counts())\n",
    "print(df['ic_others_7'].astype('category').value_counts())\n",
    "print(df['ic_others_8'].astype('category').value_counts())\n",
    "print(df['ic_others_9'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot=[\"isd_ic_mou_6\",\"isd_ic_mou_7\",\"isd_ic_mou_8\",\"isd_ic_mou_9\",\"spl_ic_mou_6\",\"spl_ic_mou_7\",\"spl_ic_mou_8\",\"spl_ic_mou_9\",\"ic_others_6\",\"ic_others_7\",\"ic_others_8\",\"ic_others_9\"]\n",
    "\n",
    "for i in plot:\n",
    "    sns.boxplot(y=df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above plots, it can be stated that imputing median value in place of null values is recommended because of presence of outliers.\n",
    "\n",
    "for i in plot:\n",
    "    df[i] = df[i].fillna(df[i].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date columns can be dropped with respect to the problem statement\n",
    "\n",
    "df = df.drop(['date_of_last_rech_6','date_of_last_rech_7','date_of_last_rech_8','date_of_last_rech_9','date_of_last_rech_data_6','date_of_last_rech_data_7','date_of_last_rech_data_8','date_of_last_rech_data_9'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns with more than 70% null values after analyzing\n",
    "\n",
    "print(df['total_rech_data_6'].astype('category').value_counts())\n",
    "print(df['total_rech_data_7'].astype('category').value_counts())\n",
    "print(df['total_rech_data_8'].astype('category').value_counts())\n",
    "print(df['total_rech_data_9'].astype('category').value_counts())\n",
    "\n",
    "print(df['max_rech_data_6'].astype('category').value_counts())\n",
    "print(df['max_rech_data_7'].astype('category').value_counts())\n",
    "print(df['max_rech_data_8'].astype('category').value_counts())\n",
    "print(df['max_rech_data_9'].astype('category').value_counts())\n",
    "\n",
    "\n",
    "# Imputing 0 in place of Nan values for the column \"total_rech_data\" \n",
    "\n",
    "df['total_rech_data_6'].fillna(0, inplace=True)\n",
    "df['total_rech_data_7'].fillna(0, inplace=True)\n",
    "df['total_rech_data_8'].fillna(0, inplace=True)\n",
    "df['total_rech_data_9'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "df = df.drop(['max_rech_data_6','max_rech_data_7','max_rech_data_8','max_rech_data_9'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns with more than 70% null values after analyzing\n",
    "\n",
    "print(df['count_rech_2g_6'].astype('category').value_counts())\n",
    "print(df['count_rech_2g_7'].astype('category').value_counts())\n",
    "print(df['count_rech_2g_8'].astype('category').value_counts())\n",
    "print(df['count_rech_2g_9'].astype('category').value_counts())\n",
    "print(df['count_rech_3g_6'].astype('category').value_counts())\n",
    "print(df['count_rech_3g_7'].astype('category').value_counts())\n",
    "print(df['count_rech_3g_8'].astype('category').value_counts())\n",
    "print(df['count_rech_3g_9'].astype('category').value_counts())\n",
    "print(df['av_rech_amt_data_6'].astype('category').value_counts())\n",
    "print(df['av_rech_amt_data_7'].astype('category').value_counts())\n",
    "print(df['av_rech_amt_data_8'].astype('category').value_counts())\n",
    "print(df['av_rech_amt_data_9'].astype('category').value_counts())\n",
    "\n",
    "# Imputing 0 in Nan values\n",
    "\n",
    "df['count_rech_2g_6'].fillna(0, inplace=True)\n",
    "df['count_rech_2g_7'].fillna(0, inplace=True)\n",
    "df['count_rech_2g_8'].fillna(0, inplace=True)\n",
    "df['count_rech_2g_9'].fillna(0, inplace=True)\n",
    "\n",
    "df['count_rech_3g_6'].fillna(0, inplace=True)\n",
    "df['count_rech_3g_7'].fillna(0, inplace=True)\n",
    "df['count_rech_3g_8'].fillna(0, inplace=True)\n",
    "df['count_rech_3g_9'].fillna(0, inplace=True)\n",
    "\n",
    "df['av_rech_amt_data_6'].fillna(0, inplace=True)\n",
    "df['av_rech_amt_data_7'].fillna(0, inplace=True)\n",
    "df['av_rech_amt_data_8'].fillna(0, inplace=True)\n",
    "df['av_rech_amt_data_9'].fillna(0, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once all the columns with null values have been appropriately treated.\n",
    "# Performing a statastical outlier treatment\n",
    "\n",
    "df1 = df.drop([\"mobile_number\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Outliers of all Numeric columns\n",
    "\n",
    "numeric = list(df1.columns)\n",
    "\n",
    "for i in numeric:\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.boxplot(y=df1[i])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier columns are treated statistically\n",
    "\n",
    "for i in numeric:\n",
    "    Q1 = df1[i].quantile(0.05)\n",
    "    Q3 = df1[i].quantile(0.95)\n",
    "    IQR = Q3 - Q1\n",
    "    hodf= df1[(df1[i] >= Q1 - 1.5*IQR) & (df1[i] <= Q3 + 1.5*IQR)]\n",
    "\n",
    "print(df1.shape)\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to find High Value Customers(HVC) we need to calculate monthly use of calls & data of a customer\n",
    "# To calculate this total amount deriving a column \"Total_amt_6_7\" from the following columns\n",
    "\n",
    "df['total_amt_6_7'] = ((df['total_rech_amt_6'] + (df['count_rech_2g_6'] + df['count_rech_3g_6'])* df['av_rech_amt_data_6'])) + (df['total_rech_amt_7'] + ((df['count_rech_2g_7'] + df['count_rech_3g_7'])* df['av_rech_amt_data_7']))/2\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all 8th Month Data\n",
    "\n",
    "df = df.drop(df.filter(regex='8$',axis=1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all 9th Month Data\n",
    "\n",
    "df = df.drop(df.filter(regex='9$',axis=1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the 70th quartile and selecting HVC on the basis of it\n",
    "# Creating HVC Dataframe : hvcdf\n",
    "\n",
    "quan_val = df['total_amt_6_7'].quantile(.70)\n",
    "print(quan_val)\n",
    "hvcdf = df.loc[df['total_amt_6_7'] >= quan_val]\n",
    "print(hvcdf.shape)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(hvcdf.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivivng churn column for dfmodel1\n",
    "\n",
    "dfmodel1 = df1.copy()\n",
    "\n",
    "dfmodel1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(row):\n",
    "    \n",
    "    if row['total_og_mou_9'] + row['total_ic_mou_9'] + row['vol_2g_mb_9'] + row['vol_3g_mb_9'] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "dfmodel1['churn'] = dfmodel1.apply (lambda row: label(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the CHURN Percentage\n",
    "\n",
    "print(\"Churn percentage is: \")\n",
    "print((dfmodel1['churn'].sum() / len(dfmodel1))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all 9th Month data from the dataframe\n",
    "\n",
    "dfmodel1 = dfmodel1.drop(dfmodel1.filter(regex='9$',axis=1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfmodel1.shape)\n",
    "print(dfmodel1.head(10))\n",
    "\n",
    "df1 = dfmodel1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature variable to X\n",
    "\n",
    "X = dfmodel1.drop(['churn'], axis=1)\n",
    "\n",
    "# Response variable to y\n",
    "\n",
    "y = dfmodel1['churn']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply scaler() to all the columns except the 'single level' variables\n",
    "\n",
    "num_vars = ['arpu_6', 'arpu_7', 'arpu_8', 'onnet_mou_6', 'onnet_mou_7', 'onnet_mou_8', 'offnet_mou_6', 'offnet_mou_7', 'offnet_mou_8', 'roam_ic_mou_6', 'roam_ic_mou_7', 'roam_ic_mou_8', 'roam_og_mou_6', 'roam_og_mou_7', 'roam_og_mou_8', 'loc_og_t2t_mou_6', 'loc_og_t2t_mou_7', 'loc_og_t2t_mou_8', 'loc_og_t2m_mou_6', 'loc_og_t2m_mou_7', 'loc_og_t2m_mou_8', 'loc_og_t2f_mou_6', 'loc_og_t2f_mou_7', 'loc_og_t2f_mou_8', 'loc_og_t2c_mou_6', 'loc_og_t2c_mou_7', 'loc_og_t2c_mou_8', 'loc_og_mou_6', 'loc_og_mou_7', 'loc_og_mou_8', 'std_og_t2t_mou_6', 'std_og_t2t_mou_7', 'std_og_t2t_mou_8', 'std_og_t2m_mou_6', 'std_og_t2m_mou_7', 'std_og_t2m_mou_8', 'std_og_t2f_mou_6', 'std_og_t2f_mou_7', 'std_og_t2f_mou_8', 'std_og_mou_6', 'std_og_mou_7', 'std_og_mou_8', 'isd_og_mou_6', 'isd_og_mou_7', 'isd_og_mou_8', 'spl_og_mou_6', 'spl_og_mou_7', 'spl_og_mou_8', 'og_others_6', 'og_others_7', 'og_others_8', 'total_og_mou_6', 'total_og_mou_7', 'total_og_mou_8', 'loc_ic_t2t_mou_6', 'loc_ic_t2t_mou_7', 'loc_ic_t2t_mou_8', 'loc_ic_t2m_mou_6', 'loc_ic_t2m_mou_7', 'loc_ic_t2m_mou_8', 'loc_ic_t2f_mou_6', 'loc_ic_t2f_mou_7', 'loc_ic_t2f_mou_8', 'loc_ic_mou_6', 'loc_ic_mou_7', 'loc_ic_mou_8', 'std_ic_t2t_mou_6', 'std_ic_t2t_mou_7', 'std_ic_t2t_mou_8', 'std_ic_t2m_mou_6', 'std_ic_t2m_mou_7', 'std_ic_t2m_mou_8', 'std_ic_t2f_mou_6', 'std_ic_t2f_mou_7', 'std_ic_t2f_mou_8', 'std_ic_mou_6', 'std_ic_mou_7', 'std_ic_mou_8', 'total_ic_mou_6', 'total_ic_mou_7', 'total_ic_mou_8', 'spl_ic_mou_6', 'spl_ic_mou_7', 'spl_ic_mou_8', 'isd_ic_mou_6', 'isd_ic_mou_7', 'isd_ic_mou_8', 'ic_others_6', 'ic_others_7', 'ic_others_8', 'total_rech_num_6', 'total_rech_num_7', 'total_rech_num_8', 'total_rech_amt_6', 'total_rech_amt_7', 'total_rech_amt_8', 'max_rech_amt_6', 'max_rech_amt_7', 'max_rech_amt_8', 'last_day_rch_amt_6', 'last_day_rch_amt_7', 'last_day_rch_amt_8', 'total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8', 'count_rech_2g_6', 'count_rech_2g_7', 'count_rech_2g_8', 'count_rech_3g_6', 'count_rech_3g_7', 'count_rech_3g_8', 'av_rech_amt_data_6', 'av_rech_amt_data_7', 'av_rech_amt_data_8', 'vol_2g_mb_6', 'vol_2g_mb_7', 'vol_2g_mb_8', 'vol_3g_mb_6', 'vol_3g_mb_7', 'vol_3g_mb_8','monthly_2g_6', 'monthly_2g_7', 'monthly_2g_8', 'sachet_2g_6', 'sachet_2g_7', 'sachet_2g_8', 'monthly_3g_6', 'monthly_3g_7', 'monthly_3g_8', 'sachet_3g_6', 'sachet_3g_7', 'sachet_3g_8', 'aon', 'aug_vbc_3g', 'jul_vbc_3g', 'jun_vbc_3g', 'sep_vbc_3g']\n",
    "\n",
    "X_train[num_vars] = scaler.fit_transform(X_train[num_vars])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing Correlation Matrix\n",
    "\n",
    "X_train.corr().round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing & running Logistic Regression on the model with RFE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(logreg, 15)\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the top 15 columns\n",
    "\n",
    "col = X_train.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Building Model using RFE Columns\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing high p value column \"loc_ic_t2m_mou_8\"\n",
    "\n",
    "X_train_sm = X_train_sm.drop([\"loc_ic_t2m_mou_8\"],1)\n",
    "col =col.drop([\"loc_ic_t2m_mou_8\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-running the model\n",
    "\n",
    "logm3 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm3.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the p values of the seleced columns are good \n",
    "# Checking for the VIF values\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train_sm.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train_sm.values, i) for i in range(X_train_sm.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing high Value VIF column \"total_ic_mou_8\"\n",
    "\n",
    "X_train_sm = X_train_sm.drop([\"total_ic_mou_8\"],1)\n",
    "col =col.drop([\"total_ic_mou_8\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-running the model\n",
    "\n",
    "logm4 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm4.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing high p value column \"isd_ic_mou_8\"\n",
    "\n",
    "X_train_sm = X_train_sm.drop([\"isd_ic_mou_8\"],1)\n",
    "col =col.drop([\"isd_ic_mou_8\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-running the model\n",
    "\n",
    "logm5 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm5.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the p values of the seleced columns are good \n",
    "# Checking for the VIF values\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train_sm.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train_sm.values, i) for i in range(X_train_sm.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing high Value VIF column \"total_og_mou_7\"\n",
    "\n",
    "X_train_sm = X_train_sm.drop([\"total_og_mou_7\"],1)\n",
    "col =col.drop([\"total_og_mou_7\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-running the model\n",
    "\n",
    "logm6 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm6.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the p values of the seleced columns are good \n",
    "# Checking for the VIF values\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train_sm.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train_sm.values, i) for i in range(X_train_sm.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing high Value VIF column \"std_ic_mou_8\"\n",
    "\n",
    "X_train_sm = X_train_sm.drop([\"std_ic_mou_8\"],1)\n",
    "col =col.drop([\"std_ic_mou_8\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-running the model\n",
    "\n",
    "logm7 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm7.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the p values of the seleced columns are good \n",
    "# Checking for the VIF values\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train_sm.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train_sm.values, i) for i in range(X_train_sm.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "y_train_pred = res.predict(X_train_sm).values.reshape(-1)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final = pd.DataFrame({'churn':y_train.values, 'Churn_Prob':y_train_pred})\n",
    "y_train_pred_final['Churn_Prob'] = y_train_pred\n",
    "\n",
    "# Creating new column 'predicted' with 1 if Churn_Prob > 0.5 else 0\n",
    "\n",
    "y_train_pred_final['predicted'] = y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deriving Metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Confusion matrix \n",
    "\n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.churn, y_train_pred_final.predicted )\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for overall accuracy\n",
    "\n",
    "print(metrics.accuracy_score(y_train_pred_final.churn, y_train_pred_final.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for sensitivity of our logistic regression model\n",
    "\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Specificity of our logistic regression model\n",
    "\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate \n",
    "\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive predictive value \n",
    "\n",
    "print (TP / float(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative predictive value\n",
    "\n",
    "print (TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ROC Curve\n",
    "\n",
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.churn, y_train_pred_final.Churn_Prob, drop_intermediate = False )\n",
    "draw_roc(y_train_pred_final.churn, y_train_pred_final.Churn_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Optimal Cutoff\n",
    "\n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating accuracy, sensitivity and specificity for various probability cutoffs.\n",
    "\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.churn, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting accuracy, sensitivity and specificity for various probabilities.\n",
    "\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above curve, selecting the best cutoff point\n",
    "\n",
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Churn_Prob.map( lambda x: 1 if x > 0.1 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for overall accuracy\n",
    "\n",
    "print(metrics.accuracy_score(y_train_pred_final.churn, y_train_pred_final.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.churn, y_train_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for sensitivity of our logistic regression model\n",
    "\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Specificity of our logistic regression model\n",
    "\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate \n",
    "\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive predictive value \n",
    "\n",
    "print (TP / float(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative predictive value\n",
    "\n",
    "print (TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Precision & Recall Scores\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_train_pred_final.churn, y_train_pred_final.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_pred_final.churn, y_train_pred_final.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision Vs Recall Curve\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.churn, y_train_pred_final.Churn_Prob)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.show()\n",
    "\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing with predictions on Test Set\n",
    "\n",
    "X_test[num_vars] = scaler.transform(X_test[num_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[col]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sm = sm.add_constant(X_test)\n",
    "y_test_pred = res.predict(X_test_sm)\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_pred to a dataframe which is an array\n",
    "\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "# Putting mobile_number to index\n",
    "y_test_df['mobile_number'] = y_test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing index for both dataframes to append them side by side \n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Appending y_test_df and y_pred_1\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column \n",
    "y_pred_final= y_pred_final.rename(columns={ 0 : 'Churn_Prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging the columns\n",
    "y_pred_final = y_pred_final.reindex_axis(['mobile_number','churn','Churn_Prob'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final['final_predicted'] = y_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.23 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "\n",
    "metrics.accuracy_score(y_pred_final.churn, y_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion3 = metrics.confusion_matrix(y_pred_final.churn, y_pred_final.final_predicted )\n",
    "confusion3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion3[1,1] # true positive \n",
    "TN = confusion3[0,0] # true negatives\n",
    "FP = confusion3[0,1] # false positives\n",
    "FN = confusion3[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hence, Logistic Regression Model Accuracy for Train & Test: 90% & 88% respectively\n",
    "# Sensitivity & Specificity of the Model for Train & Test: 85%,71% & 75%,89% respectively\n",
    "# Top Features contribuing to the Predictions are : \n",
    "# Positively corelated Features: onnet_mou_7(0.47),offnet_mou_7(0.53)\n",
    "# Negatively Correlated Features: total_og_mou_8 (-1.97), fb_user_8 (-1.3452), spl_ic_mou_8(-1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling Using PCA\n",
    "\n",
    "dfmodel2 = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfmodel2[num_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Standardization\n",
    "\n",
    "normalized_df=(df-df.mean())/df.std()\n",
    "dfmodel2 = dfmodel2.drop(num_vars,1)\n",
    "dfmodel2 = pd.concat([dfmodel2,normalized_df],axis=1)\n",
    "dfmodel2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Putting feature variable to X\n",
    "X = dfmodel2.drop(['churn'],axis=1)\n",
    "\n",
    "# Putting response variable to y\n",
    "y = dfmodel2['churn']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and Fitting PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(random_state=42)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a Scree plot\n",
    "\n",
    "var_cumu = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "fig = plt.figure(figsize=[12,8])\n",
    "plt.vlines(x=15, ymax=1, ymin=0, colors=\"r\", linestyles=\"--\")\n",
    "plt.hlines(y=1, xmax=30, xmin=0, colors=\"g\", linestyles=\"--\")\n",
    "plt.plot(var_cumu)\n",
    "plt.ylabel(\"Cumulative variance explained\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the above plot considering n_components = 17\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "pca_final = IncrementalPCA(n_components=17)\n",
    "df_train_pca = pca_final.fit_transform(X_train)\n",
    "df_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = np.corrcoef(df_train_pca.transpose())\n",
    "corr_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Correlation with a heatmap\n",
    "\n",
    "plt.figure(figsize=[15,15])\n",
    "sns.heatmap(corr_mat.round(2), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pca = pca_final.transform(X_test)\n",
    "df_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling Logistic Regression with PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "learner_pca = LogisticRegression()\n",
    "model_pca = learner_pca.fit(df_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_probs_test = model_pca.predict_proba(df_test_pca)\n",
    "\"{:2.2}\".format(metrics.roc_auc_score(y_test, pred_probs_test[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_again = PCA(0.9)\n",
    "df_train_pca2 = pca_again.fit_transform(X_train)\n",
    "df_train_pca2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_pca2 = LogisticRegression()\n",
    "model_pca2 = learner_pca2.fit(df_train_pca2, y_train)\n",
    "df_test_pca2 = pca_again.transform(X_test)\n",
    "df_test_pca2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_test2 = model_pca2.predict_proba(df_test_pca2)[:,1]\n",
    "\"{:2.2}\".format(metrics.roc_auc_score(y_test, pred_probs_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC Score from PCA : 87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling using Decision Tree with PCA\n",
    "\n",
    "dfmodel3 = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(random_state=42)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cumu = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[12,8])\n",
    "plt.vlines(x=15, ymax=1, ymin=0, colors=\"r\", linestyles=\"--\")\n",
    "plt.hlines(y=1, xmax=30, xmin=0, colors=\"g\", linestyles=\"--\")\n",
    "plt.plot(var_cumu)\n",
    "plt.ylabel(\"Cumulative variance explained\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting optimal number of components from the above graph\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "pca_final = IncrementalPCA(n_components=18)\n",
    "df_train_pca = pca_final.fit_transform(X_train)\n",
    "df_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = np.corrcoef(df_train_pca.transpose())\n",
    "corr_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,10])\n",
    "sns.heatmap(corr_mat.round(2), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pca = pca_final.transform(X_test)\n",
    "df_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing decision tree classifier \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Importing classification report and confusion matrix \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Importing packages for visualization\n",
    "\n",
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus, graphviz\n",
    "\n",
    "# Impoting GridSearchCV to find optimal max_depth & KFolds\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "    'criterion': ['gini']\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "# Instantiate the grid search model\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid = param_grid, cv = n_folds, verbose = 1)     \n",
    "\n",
    "# Fit the grid search to the data\n",
    "\n",
    "grid_search.fit(df_train_pca,y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv results\n",
    "\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the optimal accuracy score and hyperparameters\n",
    "\n",
    "print(\"Accuracy : \", grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-running the model with the above Hyperparameters\n",
    "\n",
    "# model with optimal hyperparameters\n",
    "\n",
    "dtree2 = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                                  random_state = 100,\n",
    "                                  max_depth=10, \n",
    "                                  min_samples_leaf=100,\n",
    "                                  min_samples_split=50)\n",
    "\n",
    "dtree2.fit(df_train_pca, y_train) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "dtree2.score(df_test_pca ,y_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(dfmodel3.columns[126:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the Decision tree\n",
    "\n",
    "dot_data = StringIO() \n",
    "export_graphviz(dtree2, out_file=dot_data,feature_names= features ,filled=True,rounded=True)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification metrics\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = dtree2.predict(df_test_pca)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "confusion4 = metrics.confusion_matrix(y_test,y_pred)\n",
    "confusion4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion4[1,1] # true positive \n",
    "TN = confusion4[0,0] # true negatives\n",
    "FP = confusion4[0,1] # false positives\n",
    "FN = confusion4[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hence, Accuracy of the Decision tree stands at : 91%\n",
    "# Sensitivity & Specificity at : 35% & 98%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling with Random Forest using PCA\n",
    "\n",
    "dfmodel4 = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "X = dfmodel4.drop(['churn'],axis=1)\n",
    "\n",
    "# Putting response variable to y\n",
    "y = dfmodel4['churn']\n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state = 99)\n",
    "\n",
    "\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state=42)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cumu = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[12,8])\n",
    "plt.vlines(x=15, ymax=1, ymin=0, colors=\"r\", linestyles=\"--\")\n",
    "plt.hlines(y=1, xmax=30, xmin=0, colors=\"g\", linestyles=\"--\")\n",
    "plt.plot(var_cumu)\n",
    "plt.ylabel(\"Cumulative variance explained\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "pca_final = IncrementalPCA(n_components=18)\n",
    "df_train_pca = pca_final.fit_transform(X_train)\n",
    "df_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = np.corrcoef(df_train_pca.transpose())\n",
    "corr_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,15])\n",
    "sns.heatmap(corr_mat.round(2), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pca = pca_final.transform(X_test)\n",
    "df_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing random forest classifier \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [4,8,10],\n",
    "    'min_samples_leaf': range(100, 400, 200),\n",
    "    'min_samples_split': range(200, 500, 200),\n",
    "    'n_estimators': [100,200, 300], \n",
    "    'max_features': [5, 10]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "\n",
    "grid_search.fit(df_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "\n",
    "print('Accuracy : ',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with the optimal hyperparameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(bootstrap=True,\n",
    "                             max_depth=10,\n",
    "                             min_samples_leaf=100, \n",
    "                             min_samples_split=200,\n",
    "                             max_features=10,\n",
    "                             n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "\n",
    "rfc.fit(df_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "\n",
    "predictions = rfc.predict(df_test_pca)\n",
    "\n",
    "# metrics\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "confusion5 = metrics.confusion_matrix(y_test,y_pred)\n",
    "confusion5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion5[1,1] # true positive \n",
    "TN = confusion5[0,0] # true negatives\n",
    "FP = confusion5[0,1] # false positives\n",
    "FN = confusion5[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity\n",
    "\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specificity\n",
    "\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy for Random Forest : 92% \n",
    "# Sensitivity & Specificity : 5% & 94% "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
